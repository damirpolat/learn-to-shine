# load scenario
data = read.arff("/home/damir/modeling-algorithmic-performance/Models/aslib_scenarios/SAT11-RAND/algorithm_runs.arff")
#data = read.arff("/home/damir/modeling-algorithmic-performance/Models/aslib_scenarios/SAT18-EXP/algorithm_runs.arff")
data = select(data, instance_id, algorithm, runtime)
features = read.csv("/home/damir/modeling-algorithmic-performance/Models/sat11rand_model/solvers_metrix.csv")
metrics = read.csv("/home/damir/modeling-algorithmic-performance/Models/sat11rand_model/solvers_metrix.csv")
asts = read.csv("/home/damir/modeling-algorithmic-performance/Models/sat11rand_model/ast_features.csv")
#features = read.csv("/home/damir/modeling-algorithmic-performance/Models/sat18_model/solvers_metrix.csv")
#features = select(features, Solver, Max.Indent..Total.)
colnames(features)[1] = c("algorithm")
colnames(metrics)[1] = c("algorithm")
colnames(asts)[1] = c("algorithm")
listLearners("cluster")
a=listLearners("cluster")
a
tail(a)
#task.data = data.combined
#task.data$runtime = NULL
#task.data
task = makeClusterTask(id = "k-means with features", data = data.combined)
#task.data = data.combined
#task.data$runtime = NULL
task.data = metrics
head(task.data)
#task.data = data.combined
#task.data$runtime = NULL
task.data = metrics
task.data$algorithm = NULL
head(task.data)
task = makeClusterTask(id = "k-means with features", data = task.data)
learner = makeLearner("cluster.XMeans")
mod = train(task, learner)
mod = train(learner, task)
install.packages("XMeans")
install.packages("RWeka")
install.packages("RWeka")
#task.data = data.combined
#task.data$runtime = NULL
task.data = metrics
task.data$algorithm = NULL
task = makeClusterTask(id = "k-means with features", data = task.data)
library(mlr)
task = makeClusterTask(id = "k-means with features", data = task.data)
learner = makeLearner("cluster.XMeans")
learner = makeLearner("cluster.XMeans")
mod = train(learner, task)
mod = train(learner, task)
library(dplyr)
library(ggplot2)
library(fpc)
#library(mlr3)
#library(mlr3viz)
#library(mlr3learners)
#library(mlr3tuning)
#library(mlr3filters)
library(mlr)
#library(paradox)
library(foreign)
library(qdap)
library(factoextra)
# load scenario
data = read.arff("/home/damir/modeling-algorithmic-performance/Models/aslib_scenarios/SAT11-RAND/algorithm_runs.arff")
#data = read.arff("/home/damir/modeling-algorithmic-performance/Models/aslib_scenarios/SAT18-EXP/algorithm_runs.arff")
data = select(data, instance_id, algorithm, runtime)
features = read.csv("/home/damir/modeling-algorithmic-performance/Models/sat11rand_model/solvers_metrix.csv")
metrics = read.csv("/home/damir/modeling-algorithmic-performance/Models/sat11rand_model/solvers_metrix.csv")
asts = read.csv("/home/damir/modeling-algorithmic-performance/Models/sat11rand_model/ast_features.csv")
#features = read.csv("/home/damir/modeling-algorithmic-performance/Models/sat18_model/solvers_metrix.csv")
#features = select(features, Solver, Max.Indent..Total.)
colnames(features)[1] = c("algorithm")
colnames(metrics)[1] = c("algorithm")
colnames(asts)[1] = c("algorithm")
#task.data = data.combined
#task.data$runtime = NULL
task.data = metrics
task.data$algorithm = NULL
task = makeClusterTask(id = "k-means with features", data = task.data)
learner = makeLearner("cluster.XMeans")
mod = train(learner, task)
mod
mod$learner.model$class_ids
head(task.data)
lenth(task.data$Lines..Average.)
length(task.data$Lines..Average.)
metrics
mod$learner.model$clusterer
head(plot.data)
plot.data = task.data
plot.data$cluster = mod$learner.model$class_ids
head(plot.data)
plot = ggplot(data = plot.data, aes(x = Max.Indent..Total, y = Lines..Average, color = cluster)) +
geom_point()
plot
plot = ggplot(data = plot.data, aes(x = Max.Indent..Total., y = Lines..Average., color = cluster)) +
geom_point()
plot
plot = ggplot(data = plot.data, aes(x = Max.Indent..Total., y = Lines..Average., group = cluster)) +
geom_point()
plot
plot = ggplot(data = plot.data, aes(x = Max.Indent..Total., y = Lines..Average., group = cluster)) +
geom_point(color = cluster)
plot
plot = ggplot(data = plot.data, aes(x = Max.Indent..Total., y = Lines..Average., group = cluster)) +
geom_point(aes(color = cluster))
plot = ggplot(data = plot.data, aes(x = Max.Indent..Total., y = Lines..Average., group = cluster)) +
geom_point(aes(color = cluster))
plot
plot = ggplot(data = plot.data, aes(x = Max.Indent..Total., y = Lines..Average.)) +
geom_point(aes(color = cluster))
plot
plot = ggplot(data = plot.data, aes(x = Max.Indent..Total., y = Lines..Average., color = cluster)) #+
#geom_point(aes(color = cluster))
plot
head(plot.data)
plot.data$cluster = as.factor(plot.data$cluster)
plot = ggplot(data = plot.data, aes(x = Max.Indent..Total., y = Lines..Average., color = cluster)) #+
#geom_point(aes(color = cluster))
plot
plot = ggplot(data = plot.data, aes(x = Max.Indent..Total., y = Lines..Average., color = cluster)) +
geom_point()
#geom_point(aes(color = cluster))
plot
plot.data[1:4]
length(plot.data)
library(dplyr)
library(ggplot2)
library(GGally)
library(fpc)
#library(mlr3)
#library(mlr3viz)
#library(mlr3learners)
#library(mlr3tuning)
#library(mlr3filters)
library(mlr)
#library(paradox)
library(foreign)
library(qdap)
library(factoextra)
ggpairs(plot.data, columns=1:9, aes(color = cluster)) +
ggtitle("Software Metrics")
ggpairs(plot.data, columns=1:9, aes(color = cluster)) +
ggtitle("Software Metrics")
library(lattice)
splom(iris[1:9],
groups = plot.data$cluster,
main="Software Metrics")
?ggpairs
splom(plot.data[1:9],
groups = plot.data$cluster,
main="Software Metrics")
ggpairs(plot.data, columns = 1:4, aes(color = cluster)) +
ggtitle("Software Metrics")
ggpairs(plot.data, columns = 1:4, aes(color = cluster)) +
ggtitle("Software Metrics")
library(lattice)
splom(plot.data[1:4],
groups = plot.data$cluster,
main="Software Metrics")
ggpairs(plot.data, columns = 1:3, aes(color = cluster)) +
ggtitle("Software Metrics")
ggpairs(plot.data, columns = 1:3, aes(color = cluster)) +
ggtitle("Software Metrics")
library(lattice)
splom(plot.data[1:4],
groups = plot.data$cluster,
main="Software Metrics")
ggpairs(plot.data, columns = 1:3, aes(color = cluster)) +
ggtitle("Software Metrics")
ggpairs(plot.data, columns = 1:3, aes(color = cluster)) +
ggtitle("Software Metrics")
library(lattice)
splom(plot.data[1:3],
groups = plot.data$cluster,
main="Software Metrics")
task.data = asts
task.data$algorithm = NULL
task = makeClusterTask(id = "k-means with features", data = task.data)
learner = makeLearner("cluster.XMeans")
mod = train(learner, task)
plot.data = task.data
plot.data$cluster = mod$learner.model$class_ids
plot.data$cluster = as.factor(plot.data$cluster)
plot = ggplot(data = plot.data, aes(x = Max.Indent..Total., y = Lines..Average., color = cluster)) +
geom_point()
plot = ggplot(data = plot.data, aes(x = Max.Indent..Total., y = Lines..Average., color = cluster)) +
geom_point()
plot
head(plot.data)
?learner
learner
learner$par.set
head(plot.data)
plot = ggplot(data = plot.data, aes(x = nb_edges, y = degree_variance, color = cluster)) +
geom_point()
plot
plot.data
head(asts)
ggpairs(plot.data, columns = 1:3, aes(color = cluster)) +
ggtitle("Software Metrics")
ggpairs(plot.data, columns = 1:3, aes(color = cluster)) +
ggtitle("Software Metrics")
library(lattice)
splom(plot.data[1:3],
groups = plot.data$cluster,
main="Software Metrics")
plotmatrix(plot.data[1:9])
ggpairs(plot.data[1:9])
ggpairs(plot.data[1:3])
?ggpairs
pair.plot = ggapairs(plot.data[1:3])
pair.plot = ggpairs(plot.data[1:3])
pair.plot
pair.plot = ggpairs(plot.data[1:3], aes(color = cluster))
pair.plot
plot.data$cluster
pair.plot = ggpairs(plot.data[1:3], aes(color = plot.data$cluster))
pair.plot
pair.plot = ggpairs(plot.data[1:4], aes(color = plot.data$cluster))
pair.plot
metrics_ast = read.csv("/home/damir/modeling-algorithmic-performance/Models/sat11rand_model/metrics_ast_bitwise_features.csv")
head(metrics_ast)
cluster.data = data
ids = unique(cluster.data$instance_id)
new.ids = 1:length(ids)
cluster.data$instance_id = mgsub(ids, new.ids, cluster.data$instance_id)
cluster.data$instance_id = as.integer(cluster.data$instance_id)
algos = unique(cluster.data$algorithm)
new.algos = 1:length(algos)
cluster.data$algorithm = mgsub(algos, new.algos, cluster.data$algorithm)
cluster.data$algorithm = as.integer(cluster.data$algorithm)
cluster.data$instance_id = NULL
cluster.data$algorithm = NULL
db = fpc::dbscan(cluster.data, eps = 140, MinPts = 50)
cluster.data$cluster = db$cluster
plot = ggplot(data = cluster.data, aes(x = cluster, y = runtime)) + geom_point()
plot
dbscan::kNNdistplot(cluster.data, k =  50)
abline(h = 140, lty = 2)
data.combined = merge(data, metrics_ast, by = "algorithm")
head(data)
head(metrics_ast)
# load scenario
data = read.arff("/home/damir/modeling-algorithmic-performance/Models/aslib_scenarios/SAT11-RAND/algorithm_runs.arff")
data = select(data, instance_id, algorithm, runtime)
features = read.csv("/home/damir/modeling-algorithmic-performance/Models/sat11rand_model/solvers_metrix.csv")
metrics = read.csv("/home/damir/modeling-algorithmic-performance/Models/sat11rand_model/solvers_metrix.csv")
asts = read.csv("/home/damir/modeling-algorithmic-performance/Models/sat11rand_model/ast_features.csv")
metrics_ast = read.csv("/home/damir/modeling-algorithmic-performance/Models/sat11rand_model/metrics_ast_bitwise_features.csv")
colnames(features)[1] = c("algorithm")
colnames(metrics)[1] = c("algorithm")
colnames(asts)[1] = c("algorithm")
colnames(metrics_ast)[1] = c("algorithm")
data.combined = merge(data, metrics_ast, by = "algorithm")
task.data = metrics_ast
task.data$algorithm = NULL
task = makeClusterTask(id = "k-means with features", data = task.data)
learner = makeLearner("cluster.XMeans")
mod = train(learner, task)
plot.data = task.data
plot.data$cluster = mod$learner.model$class_ids
plot.data$cluster = as.factor(plot.data$cluster)
plot = ggplot(data = plot.data, aes(x = Max.Indent..Total., y = Lines..Average., color = cluster)) +
geom_point()
plot
ggpairs(plot.data, columns = 1:3, aes(color = cluster)) +
ggtitle("Software Metrics")
ggpairs(plot.data, columns = 1:3, aes(color = cluster)) +
ggtitle("Software Metrics")
library(lattice)
library(lattice)
splom(plot.data[1:3],
groups = plot.data$cluster,
main="Software Metrics")
pair.plot = ggpairs(plot.data[1:4], aes(color = plot.data$cluster))
pair.plot
task.data = asts
task.data$algorithm = NULL
task = makeClusterTask(id = "k-means with features", data = task.data)
learner = makeLearner("cluster.XMeans")
mod = train(learner, task)
plot.data = task.data
plot.data$cluster = mod$learner.model$class_ids
plot.data$cluster = as.factor(plot.data$cluster)
plot = ggplot(data = plot.data, aes(x = nb_edges, y = degree_variance, color = cluster)) +
geom_point()
plot
pair.plot = ggpairs(plot.data[1:4], aes(color = plot.data$cluster))
pair.plot
library(aslib)
library(batchtools)
m1 = c(0.73, 0.69, 0.44, 0.55, 0.67, 0.47, 0.08,
0.15, 0.45, 0.35)
m2 = c(0.61, 0.03, 0.68, 0.31, 0.45, 0.09, 0.38,
0.05, 0.01, 0.04)
m1
m2
y = c(1, 1, 0, 0, 1, 1, 0, 0, 1, 0)
m1 = c(0.73, 0.69, 0.44, 0.55, 0.67, 0.47, 0.08,
0.15, 0.45, 0.35)
m2 = c(0.61, 0.03, 0.68, 0.31, 0.45, 0.09, 0.38,
0.05, 0.01, 0.04)
test_roc = roc(y ~ m1, plot = TRUE, print.auc = TRUE)
library(ggplot2)
library(pROC)
??roc
library(plotROC)
install.packages("plotROC")
library(plotROC)
y = c(1, 1, 0, 0, 1, 1, 0, 0, 1, 0)
m1 = c(0.73, 0.69, 0.44, 0.55, 0.67, 0.47, 0.08,
0.15, 0.45, 0.35)
m2 = c(0.61, 0.03, 0.68, 0.31, 0.45, 0.09, 0.38,
0.05, 0.01, 0.04)
#test_roc = roc(y ~ m1, plot = TRUE, print.auc = TRUE)
rocplot = ggplot(data = cbind.data.frame(y = y, m1 = m1), aes(m = m1, d = y))+ geom_roc(n.cuts=20,labels=FALSE)
rocplot = rocplot + style_roc(theme = theme_grey) + geom_rocci(fill="pink")
rocplot
install.packages("pROC")
library(pROC)
library(ggplot2)
library(plotROC)
library(pROC)
curve = roc(y ~ m1)
plot(curve)
plot(curve1, curve2)
curve1 = roc(y ~ m1)
curve2 = roc(y ~ m2)
plot(curve1, curve2)
library(ROCR)
install.packages("ROCR")
library(ggplot2)
library(plotROC)
library(ROCR)
?prediction
pred1 = prediction(m1)
pred1 = prediction(m1, y)
rocs = performance(pred1, "tpr", "fpr")
rocs
plot(rocs, col = as.list(1:lenght(m1)), main = "Test Set ROC Curves")
plot(rocs, col = as.list(1:length(m1)), main = "Test Set ROC Curves")
?plot.roc
?plot.roc.roc
?plot.performance
pred1 = prediction(m1, y)
pred2 = prediction(m2, y)
rocs = performance(list(pred1, pred2), "tpr", "fpr")
?performance
pred1 = prediction(m1, m2, y)
?prediction
pred1 = prediction(list(m1, m2), y)
pred1 = prediction(m1, y)
pred2 = prediction(m2, y)
perf1 = performance(pred1, "tpr", "fpr")
perf2 = performance(pred2, "tpr", "fpr")
plot(perf1, colorize = TRUE)
plot(perf2, add = TRUE, colorize = TRUE)
plot(perf1, colorize = TRUE)
perf2
preds = cbind(m1 = m1, m2 = m2)
head(preds)
pred.mat = prediction(preds, labels = matrix(y, nrow = length(y), ncol = 2))
perf.mat = performance(pred.mat, "tpr", "fpr")
plot(perf.mat, colorize = TRUE)
plot(perf.mat, colorize = FALSE)
plot(perf.mat, colorize = TRUE)
?plot.performance
text(locator(), labels = c("red line", "black line)"))
plot(perf.mat, colorize = TRUE)
text(locator(), labels = c("red line", "black line)"))
plot(perf.mat, colorize = TRUE)
head(pred1)
pred1
perf1
plot(perf1, colorize = TRUE)
plot(perf.mat, colorize = TRUE)
preds = cbind(m1 = m1, m2 = m2)
pred.mat = prediction(preds, labels = matrix(y, nrow = length(y), ncol = 2))
perf.mat = performance(pred.mat, "tpr", "fpr")
plot(perf.mat, colorize = TRUE)
rocplot = ggplot(data = cbind.data.frame(y = y, m1 = m1), aes(m = m1, d = y))+ geom_roc(n.cuts=20,labels=FALSE)
rocplot = rocplot + style_roc(theme = theme_grey) + geom_rocci(fill="pink")
rocplot
preds
perf.mat
RP.perf <- performance(pred, "prec", "rec")
RP.perf <- performance(pred1, "prec", "rec")
RP.perf
library(mlr)
df = generateThreshVsPerfData(pred1, measures = list(fpr, tpr, mmce))
pred1 = m1
df = generateThreshVsPerfData(pred1, measures = list(fpr, tpr, mmce))
m1
?predicyt
?predict
pred1 = cbind.data.frame(pred = m1, actual = y)
pred1
df = generateThreshVsPerfData(pred1, measures = list(fpr, tpr, mmce))
n = getTaskSize(sonar.task)
train.set = sample(n, size = round(2/3 * n))
test.set = setdiff(seq_len(n), train.set)
lrn1 = makeLearner("classif.lda", predict.type = "prob")
mod1 = train(lrn1, sonar.task, subset = train.set)
pred1 = predict(mod1, task = sonar.task, subset = test.set)
pred1
pred1$data
pred1 = prediction(m1, labels = y)
pred1
perf1 = performance(pred1, "prec")
?performance
perf1 = performance(pred1, measure = "prec")
classof(perf1)
class(perf1)
pred1 = prediction(m1, labels = y)
perf1 = performance(pred1, measure = prec)
perf1 = performance(pred1, measure = "acc")
pred1
pred1 = prediction(m1, labels = y)
perf1 = performance(pred1, measure = prec)
perf1 = performance(pred1c)
perf1 = performance(pred1)
perf1 = performance(pred1, "acc")
preds = cbind(m1 = m1, m2 = m2)
pred.mat = prediction(preds, labels = matrix(y, nrow = length(y), ncol = 2))
perf.mat = performance(pred.mat, "tpr", "fpr")
library(ggplot2)
library(plotROC)
library(ROCR)
preds = cbind(m1 = m1, m2 = m2)
pred.mat = prediction(preds, labels = matrix(y, nrow = length(y), ncol = 2))
perf.mat = performance(pred.mat, "tpr", "fpr")
ssessionInfo()
ssessionInfo()
sessionInfo()
reticulate::repl_python()
shiny::runApp('school/shiny.rstudio.com-tutorial/part-1-code')
runApp('school/shiny.rstudio.com-tutorial/part-1-code/01-template.R')
library(shiny)
?fuildPage
?fluidPage
runApp('school/shiny.rstudio.com-tutorial/part-1-code/first-app.R')
runApp('school/shiny.rstudio.com-tutorial/part-1-code/first-app.R')
runApp('school/shiny.rstudio.com-tutorial/part-1-code/first-app.R')
runApp('school/shiny.rstudio.com-tutorial/part-1-code/first-app.R')
?sliderInput
# Define UI for app that draws a histogram ----
ui = fluidPage(
# App title ----
titlePanel("Hello Shiny!"),
# Sidebar layout with input and output definitions ----
sidebarLayout(
# Sidebar panel for inputs ----
sidebarPanel(
# Input: Slider for the number of bins ----
sliderInput(inputId = "bins",
label = "Number of bins:",
min = 1,
max = 50,
value = 30)
),
# Main panel for displaying outputs ----
mainPanel(
# Output: Histogram ----
plotOutput(outputId = "distPlot")
)
)
)
# Define server logic required to draw a histogram ----
server <- function(input, output) {
# Histogram of the Old Faithful Geyser Data ----
# with requested number of bins
# This expression that generates a histogram is wrapped in a call
# to renderPlot to indicate that:
#
# 1. It is "reactive" and therefore should be automatically
#    re-executed when inputs (input$bins) change
# 2. Its output type is a plot
output$distPlot <- renderPlot({
x    <- faithful$waiting
bins <- seq(min(x), max(x), length.out = input$bins + 1)
hist(x, breaks = bins, col = "#75AADB", border = "white",
xlab = "Waiting time to next eruption (in mins)",
main = "Histogram of waiting times")
})
}
library(shiny); runApp('school/shiny.rstudio.com-tutorial/hello-app.R')
runApp("App-1", display.mode = "showcase")
runApp("hello-app", display.mode = "showcase")
getwd()
setwd("school/shiny.rstudio.com-tutorial/")
runApp("hello-app", display.mode = "showcase")
runApp("hello-app.R", display.mode = "showcase")
?rnorm
rnorm(10)
runApp('lesson2.R')
runApp('lesson2.R')
runApp('lesson2.R')
h1("My title")
runApp('lesson2.R')
runApp('lesson2.R')
getwd()
setwd("../../learn-to-shine/")
runApp('lesson2.R')
runApp('lesson2.R')
runApp('lesson2.R')
runApp('lesson2.R')
runApp('lesson2.R')
runApp('lesson2.R')
runApp('lesson2.R')
runApp('lesson2.R')
?sidebarPanel
runApp('lesson2.R')
runApp('lesson2.R')
