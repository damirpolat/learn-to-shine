geom_point()
plot
plot.data
head(asts)
ggpairs(plot.data, columns = 1:3, aes(color = cluster)) +
ggtitle("Software Metrics")
ggpairs(plot.data, columns = 1:3, aes(color = cluster)) +
ggtitle("Software Metrics")
library(lattice)
splom(plot.data[1:3],
groups = plot.data$cluster,
main="Software Metrics")
plotmatrix(plot.data[1:9])
ggpairs(plot.data[1:9])
ggpairs(plot.data[1:3])
?ggpairs
pair.plot = ggapairs(plot.data[1:3])
pair.plot = ggpairs(plot.data[1:3])
pair.plot
pair.plot = ggpairs(plot.data[1:3], aes(color = cluster))
pair.plot
plot.data$cluster
pair.plot = ggpairs(plot.data[1:3], aes(color = plot.data$cluster))
pair.plot
pair.plot = ggpairs(plot.data[1:4], aes(color = plot.data$cluster))
pair.plot
metrics_ast = read.csv("/home/damir/modeling-algorithmic-performance/Models/sat11rand_model/metrics_ast_bitwise_features.csv")
head(metrics_ast)
cluster.data = data
ids = unique(cluster.data$instance_id)
new.ids = 1:length(ids)
cluster.data$instance_id = mgsub(ids, new.ids, cluster.data$instance_id)
cluster.data$instance_id = as.integer(cluster.data$instance_id)
algos = unique(cluster.data$algorithm)
new.algos = 1:length(algos)
cluster.data$algorithm = mgsub(algos, new.algos, cluster.data$algorithm)
cluster.data$algorithm = as.integer(cluster.data$algorithm)
cluster.data$instance_id = NULL
cluster.data$algorithm = NULL
db = fpc::dbscan(cluster.data, eps = 140, MinPts = 50)
cluster.data$cluster = db$cluster
plot = ggplot(data = cluster.data, aes(x = cluster, y = runtime)) + geom_point()
plot
dbscan::kNNdistplot(cluster.data, k =  50)
abline(h = 140, lty = 2)
data.combined = merge(data, metrics_ast, by = "algorithm")
head(data)
head(metrics_ast)
# load scenario
data = read.arff("/home/damir/modeling-algorithmic-performance/Models/aslib_scenarios/SAT11-RAND/algorithm_runs.arff")
data = select(data, instance_id, algorithm, runtime)
features = read.csv("/home/damir/modeling-algorithmic-performance/Models/sat11rand_model/solvers_metrix.csv")
metrics = read.csv("/home/damir/modeling-algorithmic-performance/Models/sat11rand_model/solvers_metrix.csv")
asts = read.csv("/home/damir/modeling-algorithmic-performance/Models/sat11rand_model/ast_features.csv")
metrics_ast = read.csv("/home/damir/modeling-algorithmic-performance/Models/sat11rand_model/metrics_ast_bitwise_features.csv")
colnames(features)[1] = c("algorithm")
colnames(metrics)[1] = c("algorithm")
colnames(asts)[1] = c("algorithm")
colnames(metrics_ast)[1] = c("algorithm")
data.combined = merge(data, metrics_ast, by = "algorithm")
task.data = metrics_ast
task.data$algorithm = NULL
task = makeClusterTask(id = "k-means with features", data = task.data)
learner = makeLearner("cluster.XMeans")
mod = train(learner, task)
plot.data = task.data
plot.data$cluster = mod$learner.model$class_ids
plot.data$cluster = as.factor(plot.data$cluster)
plot = ggplot(data = plot.data, aes(x = Max.Indent..Total., y = Lines..Average., color = cluster)) +
geom_point()
plot
ggpairs(plot.data, columns = 1:3, aes(color = cluster)) +
ggtitle("Software Metrics")
ggpairs(plot.data, columns = 1:3, aes(color = cluster)) +
ggtitle("Software Metrics")
library(lattice)
library(lattice)
splom(plot.data[1:3],
groups = plot.data$cluster,
main="Software Metrics")
pair.plot = ggpairs(plot.data[1:4], aes(color = plot.data$cluster))
pair.plot
task.data = asts
task.data$algorithm = NULL
task = makeClusterTask(id = "k-means with features", data = task.data)
learner = makeLearner("cluster.XMeans")
mod = train(learner, task)
plot.data = task.data
plot.data$cluster = mod$learner.model$class_ids
plot.data$cluster = as.factor(plot.data$cluster)
plot = ggplot(data = plot.data, aes(x = nb_edges, y = degree_variance, color = cluster)) +
geom_point()
plot
pair.plot = ggpairs(plot.data[1:4], aes(color = plot.data$cluster))
pair.plot
library(aslib)
library(batchtools)
m1 = c(0.73, 0.69, 0.44, 0.55, 0.67, 0.47, 0.08,
0.15, 0.45, 0.35)
m2 = c(0.61, 0.03, 0.68, 0.31, 0.45, 0.09, 0.38,
0.05, 0.01, 0.04)
m1
m2
y = c(1, 1, 0, 0, 1, 1, 0, 0, 1, 0)
m1 = c(0.73, 0.69, 0.44, 0.55, 0.67, 0.47, 0.08,
0.15, 0.45, 0.35)
m2 = c(0.61, 0.03, 0.68, 0.31, 0.45, 0.09, 0.38,
0.05, 0.01, 0.04)
test_roc = roc(y ~ m1, plot = TRUE, print.auc = TRUE)
library(ggplot2)
library(pROC)
??roc
library(plotROC)
install.packages("plotROC")
library(plotROC)
y = c(1, 1, 0, 0, 1, 1, 0, 0, 1, 0)
m1 = c(0.73, 0.69, 0.44, 0.55, 0.67, 0.47, 0.08,
0.15, 0.45, 0.35)
m2 = c(0.61, 0.03, 0.68, 0.31, 0.45, 0.09, 0.38,
0.05, 0.01, 0.04)
#test_roc = roc(y ~ m1, plot = TRUE, print.auc = TRUE)
rocplot = ggplot(data = cbind.data.frame(y = y, m1 = m1), aes(m = m1, d = y))+ geom_roc(n.cuts=20,labels=FALSE)
rocplot = rocplot + style_roc(theme = theme_grey) + geom_rocci(fill="pink")
rocplot
install.packages("pROC")
library(pROC)
library(ggplot2)
library(plotROC)
library(pROC)
curve = roc(y ~ m1)
plot(curve)
plot(curve1, curve2)
curve1 = roc(y ~ m1)
curve2 = roc(y ~ m2)
plot(curve1, curve2)
library(ROCR)
install.packages("ROCR")
library(ggplot2)
library(plotROC)
library(ROCR)
?prediction
pred1 = prediction(m1)
pred1 = prediction(m1, y)
rocs = performance(pred1, "tpr", "fpr")
rocs
plot(rocs, col = as.list(1:lenght(m1)), main = "Test Set ROC Curves")
plot(rocs, col = as.list(1:length(m1)), main = "Test Set ROC Curves")
?plot.roc
?plot.roc.roc
?plot.performance
pred1 = prediction(m1, y)
pred2 = prediction(m2, y)
rocs = performance(list(pred1, pred2), "tpr", "fpr")
?performance
pred1 = prediction(m1, m2, y)
?prediction
pred1 = prediction(list(m1, m2), y)
pred1 = prediction(m1, y)
pred2 = prediction(m2, y)
perf1 = performance(pred1, "tpr", "fpr")
perf2 = performance(pred2, "tpr", "fpr")
plot(perf1, colorize = TRUE)
plot(perf2, add = TRUE, colorize = TRUE)
plot(perf1, colorize = TRUE)
perf2
preds = cbind(m1 = m1, m2 = m2)
head(preds)
pred.mat = prediction(preds, labels = matrix(y, nrow = length(y), ncol = 2))
perf.mat = performance(pred.mat, "tpr", "fpr")
plot(perf.mat, colorize = TRUE)
plot(perf.mat, colorize = FALSE)
plot(perf.mat, colorize = TRUE)
?plot.performance
text(locator(), labels = c("red line", "black line)"))
plot(perf.mat, colorize = TRUE)
text(locator(), labels = c("red line", "black line)"))
plot(perf.mat, colorize = TRUE)
head(pred1)
pred1
perf1
plot(perf1, colorize = TRUE)
plot(perf.mat, colorize = TRUE)
preds = cbind(m1 = m1, m2 = m2)
pred.mat = prediction(preds, labels = matrix(y, nrow = length(y), ncol = 2))
perf.mat = performance(pred.mat, "tpr", "fpr")
plot(perf.mat, colorize = TRUE)
rocplot = ggplot(data = cbind.data.frame(y = y, m1 = m1), aes(m = m1, d = y))+ geom_roc(n.cuts=20,labels=FALSE)
rocplot = rocplot + style_roc(theme = theme_grey) + geom_rocci(fill="pink")
rocplot
preds
perf.mat
RP.perf <- performance(pred, "prec", "rec")
RP.perf <- performance(pred1, "prec", "rec")
RP.perf
library(mlr)
df = generateThreshVsPerfData(pred1, measures = list(fpr, tpr, mmce))
pred1 = m1
df = generateThreshVsPerfData(pred1, measures = list(fpr, tpr, mmce))
m1
?predicyt
?predict
pred1 = cbind.data.frame(pred = m1, actual = y)
pred1
df = generateThreshVsPerfData(pred1, measures = list(fpr, tpr, mmce))
n = getTaskSize(sonar.task)
train.set = sample(n, size = round(2/3 * n))
test.set = setdiff(seq_len(n), train.set)
lrn1 = makeLearner("classif.lda", predict.type = "prob")
mod1 = train(lrn1, sonar.task, subset = train.set)
pred1 = predict(mod1, task = sonar.task, subset = test.set)
pred1
pred1$data
pred1 = prediction(m1, labels = y)
pred1
perf1 = performance(pred1, "prec")
?performance
perf1 = performance(pred1, measure = "prec")
classof(perf1)
class(perf1)
pred1 = prediction(m1, labels = y)
perf1 = performance(pred1, measure = prec)
perf1 = performance(pred1, measure = "acc")
pred1
pred1 = prediction(m1, labels = y)
perf1 = performance(pred1, measure = prec)
perf1 = performance(pred1c)
perf1 = performance(pred1)
perf1 = performance(pred1, "acc")
preds = cbind(m1 = m1, m2 = m2)
pred.mat = prediction(preds, labels = matrix(y, nrow = length(y), ncol = 2))
perf.mat = performance(pred.mat, "tpr", "fpr")
library(ggplot2)
library(plotROC)
library(ROCR)
preds = cbind(m1 = m1, m2 = m2)
pred.mat = prediction(preds, labels = matrix(y, nrow = length(y), ncol = 2))
perf.mat = performance(pred.mat, "tpr", "fpr")
ssessionInfo()
ssessionInfo()
sessionInfo()
reticulate::repl_python()
shiny::runApp('school/shiny.rstudio.com-tutorial/part-1-code')
runApp('school/shiny.rstudio.com-tutorial/part-1-code/01-template.R')
library(shiny)
?fuildPage
?fluidPage
runApp('school/shiny.rstudio.com-tutorial/part-1-code/first-app.R')
runApp('school/shiny.rstudio.com-tutorial/part-1-code/first-app.R')
runApp('school/shiny.rstudio.com-tutorial/part-1-code/first-app.R')
runApp('school/shiny.rstudio.com-tutorial/part-1-code/first-app.R')
?sliderInput
setwd("school/Spring2020/regression_analysis/project/")
data = read.csv("project_data.csv", header = TRUE)
head(data)
summary(data)
data = read.csv("project_data.csv", header = TRUE)
head(data)
summary(data)
colnames(data)[, 2:length(data)]
colnames(data)
colnames(data)[2:length(data)]
setwd("../midterm/")
data = read.csv("Snowfall.xlsx")
library(gdata)
library(gdata)
data = read.xls("Snowfall.xlsx")
head(data)
data
scatter(data)
library(gdata)
library(ggplot2)
library(GGally)
library(reshape2)
library(ggfortify)
data = read.xls("Snowfall.xlsx")
scatter = ggpairs(data)
data$City = NULL
scatter = ggpairs(data)
scatter
matrix = cor(data)
matrix
data = read.xls("Snowfall.xlsx")
scatter = ggpairs(data)
data = read.xls("Snowfall.xlsx")
plot.data = data
plot.data$CITIES = NULL
scatter = ggpairs(plot.data)
plot.dat
plot.data
data = read.xls("Snowfall.xlsx")
plot.data = data
plot.data$City = NULL
scatter = ggpairs(plot.data)
scatter
matrix = cor(plot.data)
matrix
plot(plot.data)
model = lm(data$AVG_SNOW ~ data$ELEVATION)
model
model = lm(data$AVG_SNOW ~ data$ELEVATION)
model
summary(model)
confint(model)
confint(model)
anova(model)
autoplot(linearfit, label.size = 3)
autoplot(model, label.size = 3)
model = lm(data$AVG_SNOW ~ data$ELEVATION + data$LATITUDE)
model
model = lm(data$AVG_SNOW ~ data$ELEVATION + data$LATITUDE)
model = lm(data$AVG_SNOW ~ data$ELEVATION + data$LATITUDE)
model
model$model
p = predict(model, c(2000, 44))
colnames(data)
new.data = data.frame(colnames(data)[3] = 2000, colnames(data)[4] = 44)
new.data = data.frame(ELEVATION = 2000, LATITUDE = 44)
new.data
new.data = data.frame(ELEVATION = 2000, LATITUDE = 44)
p = predict(model, newdata = new.data)
p
new.data = data.frame(ELEVATION = 2000, LATITUDE = 44)
p = predict(model, new.data)
p
?predicy
?predict
new.data = data.frame(ELEVATION = 2000, LATITUDE = 44)
p = predict(model, newdata = new.data)
p
new.data
model
model$coefficients
length(data$City)
model = lm(data$AVG_SNOW ~ data$ELEVATION + data$LATITUDE)
model
new.data = data.frame(ELEVATION = 2000, LATITUDE = 44)
p = predict(model, newdata = new.data)
model = lm(data = data, AVG_SNOW ~ ELEVATION + LATITUDE)
model
new.data = data.frame(ELEVATION = 2000, LATITUDE = 44)
p = predict(model, newdata = new.data)
p
new.data = data.frame(ELEVATION = 2000, LATITUDE = 44)
p = predict(model, newdata = new.data)
p
anova(model)
summary(model)
summary(model)
knit_with_parameters('~/school/Spring2020/regression_analysis/midterm/midterm.Rmd')
summary(model)
getwd()
setwd("~/learn-to-shine/")
library(scholar)
getwd()
install.packages("scholar")
library(scholar)
id = 'P37OkUUAAAAJ'
l = get_profile(id)
l$name
l$affiliation
l$fields
l$homepage
get_citation_history(id)
predict_h_index(id)
id
predict_h_index(id)
get_oldest_article(id)
l$total_cites
l$coauthors
help(scholar)
vignette(scholar)
plot_coauthors(id)
coauthor_network = get_coauthors(id)
coauthor_network = get_coauthors(id)
plot_coauthors(coauthor_network)
cite(alsib)
cite(aslib)
cite(ggplot)
cite(shiny)
library(shiny)
cite(shiny)
cite(scholar)
?cite
cite("scholar")
library(mlr)
cite("mlr")
cite(mlr)
citation(mlr)
citation("mlr")
citation("shiny")
citation("llama")
a=citation("llama")
citation("shiny")
l$fields
l$total_cites
get_publications(id)
a=get_publications(id)
a$title
typeof(a)
head(a)
a
llama=citation("llama")
l=citation("llama")
a=get_publications(id)
grep(l, a)
any(a %like% l)
library(data.table)
any(a %like% l)
l
any(a %like% "llama: Leveraging Learning to Automatically Manage Algorithms")
a$title
any(a$title %like% "LLAMA: leveraging learning to automatically manage algorithms")
any(a$title %like% "llama")
match = any(a$title %like% "llama")
match
match = which.any(a$title %like% "llama")
match("llama", a$title)
match("llama" %in% a$title)
sapply(a$title, function(y) grep(y, "llama"))
m=sapply(a$title, function(y) grep(y, "llama"))
head(m)
m=sapply(a$title, function(y) grep(y, "LLAMA"))
head(m)
a$title
m[[10]]
m=sapply(a$title, function(y) grep(y, "LLAMA")[1])
m
x <- c("arm","foot","lefroo", "bafoobar")
r <- c("ar","^ba","$m","foo")
sapply(r, function(y) grep(y,x)[1])
l
lc = c("llama")
sapply(r, function(y) grep(y,lc)[1])
sapply(a$title, function(y) grep(y,lc)[1])
lc
x
r
typeof(x)
class(x)
class(a$title)
titles = a$title
class(titles)
titles = lapply(titles, as.charactter)
titles = lapply(titles, as.character)
class(titles)
head(titles)
class(x)
class(titles)
titles = unlist(titles)
class(titles)
head(titles)
sapply(titles, function(y) grep(y,lc)[1])
matches = sapply(titles, function(y) grep(y,lc)[1])
matches
head(matches)
head(matches, 10)
lc
lc = c("LLAMA")
matches = sapply(titles, function(y) grep(y,lc)[1])
head(matches, 10)
grep("LLAMA: leveraging learning to automatically manage algorithms", "llama")
?grep
grep("LLAMA: leveraging learning to automatically manage algorithms", "llama", ignore.case = TRUE)
grep("LLAMA: leveraging learning to automatically manage algorithms", pattern = "llama", ignore.case = TRUE)
grep(x = "LLAMA: leveraging learning to automatically manage algorithms", pattern = "llama", ignore.case = TRUE)
matches = sapply(titles, function(y) grep(x = y, pattern = lc, ignore.case = TRUE)[1])
head(matches, 10)
which.max(matches)
library(rcrossref)
install.packages(rcrossref)
install.packages("rcrossref")
libraryrcrossref")
libraryr("crossref")
library("crossref")
library("rcrossref")
cr_citation_count(doi="10.1371/journal.pone.0042793")
library(cranlog)
library(cranlogs)
install.packages(cranlogs)
install.packages("cranlogs")
library("cranlogs")
help(cranlogs)
vignette(cranlogs)
cran_downloads()
cran_downloads(when = "last-week")
cran_downloads(when = "last-week", package = c("llama"))
citation("llama")
library(fulltext)
install.packages("fulltext")
install.packages("crminer")
install.packages("pdftools")
install.packages("pdftools")
install.packages("fulltext")
library("fulltext")
res1 <- ft_search(query = "Protein measurement with the folin phenol reagent", from = "crossref")
res1 <- ft_links(res1)
res1$crossref$ids
rcrossref::cr_citation_count(res1$crossref$ids[1])
res1 <- ft_search(query = "llama", from = "crossref")
res1
res1 <- ft_links(res1)
res1
res1$crossref$ids
rcrossref::cr_citation_count(res1$crossref$ids[1])
citation("llama")
citation("ggplot")
librayr("ggplot2")
library("ggplot2")
citation("ggplot")
citation("ggplot2")
cite = citation("ggplot2")
cite
